

# Сравнение библиотек машинного обучения: scikit-learn, TensorFlow и PyTorch

Данный проект посвящен сравнительному анализу трех популярных библиотек машинного обучения: **scikit-learn**, **TensorFlow** и **PyTorch**. Реализованы задачи **регрессии** и **классификации** с использованием каждой из этих библиотек. Проведено сравнение их производительности, качества моделей и удобства использования.

## Содержание

1. [Описание проекта](#описание-проекта)
2. [Используемые технологии](#используемые-технологии)
3. [Данные](#данные)
4. [Результаты](#результаты)
   - [Задача регрессии](#задача-регрессии)
   - [Задача классификации](#задача-классификации)
5. [Выводы](#выводы)
6. [Запуск проекта](#запуск-проекта)
7. [Файлы с результатами](#файлы-с-результатами)
8. [Автор](#автор)
9. [Лицензия](#лицензия)

---

## Описание проекта

Цель проекта — сравнить производительность и удобство использования библиотек **scikit-learn**, **TensorFlow** и **PyTorch** при решении задач регрессии и классификации. Для этого были построены модели с одинаковой архитектурой и гиперпараметрами на одних и тех же данных.

## Используемые технологии

- **Язык программирования:** Python 3
- **Библиотеки и фреймворки:**
  - **scikit-learn**
  - **TensorFlow**
  - **Keras** (в составе TensorFlow)
  - **PyTorch**
  - **NumPy**
  - **pandas**
  - **Matplotlib**
  - **Seaborn**
- **Среда выполнения:**
  - **Google Colab**

## Данные

- **Задача регрессии:** [California Housing Dataset](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset)
- **Задача классификации:** [MNIST Dataset](https://www.openml.org/d/554)

## Результаты

### Задача регрессии

**Таблица результатов регрессии:**

| Задача    | Библиотека   | Модель          |   Время обучения (сек.) |   MSE   |   MAE   |   R²    |
|-----------|--------------|-----------------|-------------------------|---------|---------|---------|
| Регрессия | scikit-learn | MLPRegressor    |            8.3100       | 0.2828  | 0.3587  | 0.7842  |
| Регрессия | TensorFlow   | Нейронная сеть  |           54.1329       | 0.2796  | 0.3623  | 0.7866  |
| Регрессия | PyTorch      | Нейронная сеть  |           15.1306       | 0.3092  | 0.3845  | 0.7640  |

**Примечания:**

- **Время обучения (сек.):** Время, затраченное на обучение модели, измеренное в секундах.
- **MSE (Mean Squared Error):** Среднеквадратичная ошибка на тестовом наборе данных.
- **MAE (Mean Absolute Error):** Средняя абсолютная ошибка на тестовом наборе данных.
- **R² (Коэффициент детерминации):** Показатель, описывающий долю дисперсии зависимой переменной, объясняемую моделью.

### Задача классификации

**Таблица результатов классификации:**

| Задача          | Библиотека    | Модель          | Время обучения (сек.) | Точность (Accuracy) | Точность (Precision) | Полнота (Recall) | F1-мера | ROC AUC | Log Loss |
|-----------------|---------------|-----------------|-----------------------|---------------------|----------------------|------------------|---------|---------|----------|
| Классификация   | PyTorch       | Нейронная сеть  | 59.5483               | 0.9648              | 0.9654               | 0.9648           | 0.9647  | 0.9991  | 0.1438   |
| Классификация   | TensorFlow    | Нейронная сеть  | 68.5103               | 0.9616              | 0.9620               | 0.9616           | 0.9616  | 0.9987  | 0.1268   |
| Классификация   | scikit-learn  | MLPClassifier   | 120.6116              | 0.9723              | 0.9723               | 0.9723           | 0.9723  | 0.9992  | 0.1551   |

**Примечания:**

- **Время обучения (сек.):** Время, затраченное на обучение модели, измеренное в секундах.
- **Точность (Accuracy):** Доля правильно классифицированных примеров среди всех примеров тестового набора данных.
- **Точность (Precision):** Доля корректно предсказанных положительных классов среди всех примеров, предсказанных моделью как положительные.
- **Recall (Полнота):** Доля корректно предсказанных положительных классов среди всех фактически положительных примеров в тестовом наборе данных.
- **F1-мера:** Гармоническое среднее между Precision и Recall; метрика, используемая для оценки баланса между точностью и полнотой модели.
- **ROC AUC (Area Under the ROC Curve):** Площадь под кривой ошибок (Receiver Operating Characteristic); метрика, отражающая способность модели различать между положительными и отрицательными классами. Значение ROC AUC приближается к 1 для идеальной модели.
- **Log Loss (Логарифмическая функция потерь):** Метрика, измеряющая качество классификационных моделей, прогнозирующих вероятности принадлежности к классу. Меньшие значения Log Loss указывают на более точные вероятностные прогнозы.

## Выводы

### Задача регрессии

*Точность моделей:*

**Модель MLPRegressor из scikit-learn** показала хорошие результаты, с MSE 0.2828 и R² 0.7842, что сопоставимо с метриками нейронных сетей.
**Модель на TensorFlow** продемонстрировала **наилучшие метрики** среди всех трех библиотек в задаче регрессии, достинув наименьшего MSE (0.2796) и наибольшего R² (0.7866).
**Модель на PyTorch** также показала приемлемые результаты, однако ее метрики были немного ниже по сравнению с остальными моделями (MSE 0.3092, R² 0.7640).

*Время обучения:*

**scikit-learn** продемонстрировал самое быстрое время обучения (8.3100 секунд), что делает его эффективным для быстрого прототипирования и оценки моделей.
**PyTorch** показал среднее время обучения (15.1306 секунд), быстрее, чем TensorFlow, но медленнее по сравнению с scikit-learn.
**TensorFlow** потребовал наибольшее время обучения (54.1329 секунд).

*Удобство использования:*

**scikit-learn** отличается простотой использования и идеален для быстрого прототипирования благодаря высокоуровневым интерфейсам и минимальным требованиям к настройке.
**TensorFlow и PyTorch** предоставляют более гибкие возможности для настройки и масштабирования моделей, что позволяет создавать более сложные архитектуры, но требует большего объёма кода и глубинного понимания нейронных сетей.

### Задача классификации

*Точность моделей:*

**Модель MLPClassifier из scikit-learn** достигла наибольшей точности среди всех моделей (Accuracy 0.9723), превосходя нейронные сети на TensorFlow и PyTorch.
**Модель на PyTorch** показала высокие результаты с Accuracy 0.9648, демонстрируя конкурентоспособность с другими фреймворками.
**Модель на TensorFlow** также показала достойные результаты с Accuracy 0.9616, немного уступая моделям на PyTorch и scikit-learn.

*Время обучения:*

**PyTorch** обучился быстрее (59.5483 секунд), чем TensorFlow, и почти в два раза быстрее по сравнению с scikit-learn.
**TensorFlow** потребовал немного больше времени для обучения (68.5103 секунд), что может быть оправдано при использовании расширенных возможностей и оптимизаций.
**scikit-learn** имел самое длительное время обучения (120.6116 секунд).

*Удобство использования:*

**scikit-learn** предоставляет простой и интуитивно понятный интерфейс, позволяя быстро реализовать модели классификации без глубокого погружения в детали нейронных сетей.
**TensorFlow и PyTorch** предлагают широкие возможности для создания и настройки сложных моделей, что важно для задач, требующих высокой степени кастомизации, но может потребовать больше времени на разработку и отладку.

## Общие выводы

**Баланс между точностью и временем обучения:**

**scikit-learn** обеспечивает быстрый старт и высокую точность в задачах регрессии и классификации, с минимальным временем настройки и обучения.

**PyTorch** демонстрирует хороший баланс между временем обучения и качеством модели, особенно в задачах классификации.

**TensorFlow** предоставляет возможности для построения оптимизированных и точных моделей, но может потребовать больше времени на обучение.

**Выбор инструмента в зависимости от задачи:**

Для **быстрого прототипирования** и решения стандартных задач рекомендуется использовать **scikit-learn**.
При необходимости **гибкой настройки** моделей и реализации **сложных архитектур нейронных сетей** стоит обратить внимание на **TensorFlow** и **PyTorch**.
**PyTorch** может быть предпочтительным выбором для тех, кто ценит более питоновский стиль кодирования и облегченное отладку благодаря динамическому вычислительному графу.
**TensorFlow** может предложить преимущества при разработке моделей **для производственных сред** и мобильных устройств благодаря инструментам оптимизации и поддержки различных платформ.

**Для задач, где важна скорость разработки и простота реализации**, рекомендуется использовать **scikit-learn**, особенно если модели показывают достаточную точность.
**Если требуется высокая точность и есть потребность в кастомизации модели**, стоит рассмотреть использование **PyTorch** или **TensorFlow**, взвесив при этом затраты времени на обучение и настройку.
**При выборе между PyTorch и TensorFlow** важно учитывать опыт команды разработчиков, требования к производительности и интеграции, а также специфические особенности проекта.

*Примечание:* Все результаты и выводы могут варьироваться в зависимости от специфики задачи и параметров моделей.


## Запуск проекта

Проект реализован в Google Colab Notebook.

### Шаги для запуска:

1. **Открыть Notebook:**

   - [Google Colab Notebook](https://colab.research.google.com/drive/1AeKPnoIKNePeo1r2EQIQxBLCQlEnHlM3?usp=sharing)

2. **Запустить все ячейки:**

   - В меню выберите **Runtime** > **Run all** (или **Среда выполнения** > **Выполнить все**).

3. **Требования:**

   - Учетная запись Google для доступа к Colab.
   - Подключение к Интернету.

4. **Аппаратное ускорение (рекомендуется):**

   - Используйте GPU для ускорения обучения моделей:
     - В меню выберите **Runtime** > **Change runtime type** (или **Среда выполнения** > **Сменить тип среды выполнения**).
     - В поле **Hardware accelerator** выберите **GPU**.

## Файлы с результатами

- **Результаты обучения** и метрики моделей **будут сохранены** в формате JSON в папке `results/`, **после команды выполнить все**.
- Примеры файлов результатов:
  - `results_sklearn_regression.json`
  - `results_tensorflow_regression.json`
  - `results_pytorch_regression.json`

## Автор

- **[Владимир]**
  - Email: [vovparya@gmail.com](mailto:vovparya@gmail.com)
  - GitHub: [https://github.com/vovparya](https://github.com/vovparya)

## Лицензия

Проект распространяется под лицензией [MIT](LICENSE).

---

- **Зависимости:**
  - Файл `requirements.txt` содержит список зависимостей для установки необходимых библиотек, если вы будете запускать проект локально.

**Контакты и поддержка:**

Если у вас есть вопросы или предложения по проекту, пожалуйста, свяжитесь со мной по электронной почте или через GitHub.
